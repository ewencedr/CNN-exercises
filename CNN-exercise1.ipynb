{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7Z7pl_YN9KK"
   },
   "source": [
    "# CNN Exercise 1: Rebuilding LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dahpSd3BN9KN"
   },
   "source": [
    "Created by Cedric Ewen in 2023\n",
    "\n",
    "Credits to Bogdan Wiederspan who inspired this exercise with his exercice from the last years deep learning school and to [this blog post](https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118) that gave a good baseline for the exercise.\n",
    "Thanks to Github Copilot for writing the description of this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYmn0uZxN9KP"
   },
   "source": [
    "# History\n",
    "Machine learning is a topic that is researched for quite a long time. Biggest problem in the past was the lack of computational ressources. Especially image recognition was terrible in this department, since the analyzation of pictures needed huge feed-forward-networks (bad scaling of parameter numbers).\n",
    "\n",
    "Feed-forward-networks are a bad choice to analyze images, since the learned mapping is not translation-invariant. This means, that the network could not recognize for example a deer, when the deer was not centered.\n",
    "\n",
    "LeNet-5 was one of the earliest convolutional neural networks and promoted the development of deep learning. The main benefit of convolutional networks is their invariance in translation. The other benefit of this approach is the reduction of learnable parameters by introduction of convolutions.\n",
    "\n",
    "We will recreate the LeNet-5 network to train a model on MNIST dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qXmdFQ2N9KQ"
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L0nv-kdN9KS",
    "outputId": "e8fe5dcf-d858-47d8-f384-30eecfdc0b81"
   },
   "outputs": [],
   "source": [
    "# device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56UNjo3oN9KU"
   },
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3xT4DgdN9KU"
   },
   "source": [
    "The MNIST (Modified National Institute of Standards and Technology database) dataset is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. This set has been studied so much that it is often called the \"Hello World\" of Machine Learning. Whenever people come up with a new classification algorithm they are curious to see how it will perform on MNIST, and anyone who learns Machine Learning tackles this dataset sooner or later.\n",
    "\n",
    "PyTorch provides a number of datasets in torchvison.datasets. We will download the MNIST dataset from there. The following code downloads the MNIST dataset, and creates a training and test dataset. The training dataset contains 60,000 images and the test dataset contains 10,000 images. Each image is a 28x28 grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdeRlO-IN9KV",
    "outputId": "64838f49-70c4-43f5-dcd8-59be5235280d"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3P0K0GbN9KW"
   },
   "source": [
    "It is important to first get a feeling for the data. Therefore, we will first plot some of the images and their corresponding labels.\n",
    "\n",
    "We also have a look on the shape of the data. The shape of the data is important for the design of the network. In the following cell, one can see that the shape is (60000, 28, 28). This means that we have 60000 images of size 28x28 pixels. The images are grayscale, meaning that they have only one color channel. If the images were RGB images, the shape would be (60000, 28, 28, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gnfmVI9N9KY",
    "outputId": "1b0e4e43-95d3-4b3b-da8b-60f395a278f8"
   },
   "outputs": [],
   "source": [
    "print(f\"Shape of training data: {train_data.data.size()}\")\n",
    "print(f\"Shape of test data: {test_data.data.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "-sFrzD_-N9KZ",
    "outputId": "2a6528ea-7583-4fa1-e36b-bc11dfb9323b"
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsB24rTwN9Ka"
   },
   "source": [
    "During training, we usually want to pass samples in 'minibatches', so small subsets of the training dataset, instead of passing all the training data at once. This is because passing all the training data through the network at once is computationally expensive, and it is also more difficult for the network to learn from all the training data at once. The number of samples in a minibatch is called the 'batch size'. The batch size is a hyperparameter that we can tune to make the network learn better. The batch size is usually a power of 2, e.g. 32, 64, 128, 256, 512, etc. to optimally utilize the hardware. In this exercise, we will use a batch size of 64.\n",
    "\n",
    "In pytorch, a dataloader is an object that can be used to pass minibatches of data to the network. We can create a dataloader from a dataset object. The dataloader will automatically split the dataset into minibatches of the specified batch size. We can then iterate over the dataloader to get minibatches of data. The dataloader will automatically shuffle the data at the start of each epoch (an epoch is a full pass through the training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpfGqQ-9N9Kb"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1),\n",
    "\n",
    "    'test'  : torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEkKQmyKN9Kc"
   },
   "source": [
    "# The Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6lMIAS_N9Kc"
   },
   "source": [
    "We will now recreate one of the first convolutional neural networks, LeNet-5, which was introduced by Yann LeCun et al. in 1998. This network was used to classify handwritten digits of the MNIST dataset. The network consists of two convolutional layers, two pooling layers and three fully connected layers. The network architecture is shown below.\n",
    "![image.png](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/2560px-Comparison_image_neural_networks.svg.png)\n",
    "On the right, we see a much more advanced version of the LeNet-5, called AlexNet. Its quite interesting how similar, but yet so different they are.\n",
    "AlexNet is much more advanced than the plain old LeNet.\n",
    "\n",
    "Could you think of some reasons why:\n",
    "- they changed all sigmoid functions to ReLu\n",
    "- they changed the Pooling from average to max\n",
    "- they use 3 conv-layers with small window size insted of one with bigger kernel size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEptsf8MN9Kd"
   },
   "source": [
    "In general Conv-networks can be separated into 2 blocks:\n",
    "- conv-part (filters)\n",
    "- fully connected network\n",
    "\n",
    "In the convolutional-part of the network filters are trained to detect different propeties. They workout the different features of the image. These processed information are then used as input of a fully connected network to classify the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MfG0fOHN9Kd"
   },
   "source": [
    "## Build LeNet-5 with PyTorch:\n",
    "Lets build the model. We start with a Python class that inherits from nn.Module. In the init function we define the layers of the network. In the forward function we define the forward pass of the network.\n",
    "\n",
    "A list of possible layers can be found [here](https://pytorch.org/docs/stable/nn.html).\n",
    "\n",
    "By looking at the Picture of LeNet we need a ***Linear Layer, a Pooling Layer*** and atleast some kind of ***ConvND*** layer (which Dimension? Remember your input data shape!).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFdGLACcN9Ke"
   },
   "source": [
    "To help you a little in building the network the start and end is already given. Compare the code of the layer with the Image of LeNet to get a better understand what they do!\n",
    "\n",
    "Try to answer the following questions while learning how to use PyTorch. PyTorch error messanges help you to understand whats happening, but also the ```print(model)``` and the ```torchsummary.summary``` commands.\n",
    "- Which properties do the layer types have and what do they do?\n",
    "- Why do we flatten the output?\n",
    "- What is the shape after flatten?\n",
    "- What work is done by the dense layers?\n",
    "- Why do we use a softmax activation function at the end?\n",
    "- What is the sum of the softmax function outputs?\n",
    "- Where do the weights come from? How can one calculate the number of weights in a layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDBTw6fuN9Ke"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #TODO: define the layers\n",
    "\n",
    "        self.conv1 =\n",
    "            nn.Conv2d(\n",
    "                in_channels=?,\n",
    "                out_channels=?,\n",
    "                kernel_size=?,\n",
    "                stride=?,\n",
    "                padding=?,\n",
    "            ),\n",
    "        self.linear = nn.Linear(?, ?))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #TODO: run layer\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3NxxtwJN9Kf",
    "outputId": "d1e88926-fdf8-4a5e-dbd9-c7219bbd31eb"
   },
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QB3cxcqON9Kg"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(cnn, (1, 28, 28), batch_size=64, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAVMhZrwN9Kh"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYHWK040N9Ki"
   },
   "source": [
    "Now that we have the model, we can train it. We will use the Adam optimizer, which is a popular optimizer along with SGD (Stochastic Gradient Descent). We will also use the cross entropy loss function, which is the most common loss function for classification problems. Note that the CrossEntropyLoss function in PyTorch applies a softmax function to the output layer before calculating the loss. This means that we do not need to add a softmax layer to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3Ec_kuvN9Ki",
    "outputId": "a649c880-2968-49a5-94c2-d5ba819fa7c5"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vT4bc6k9Oi1D"
   },
   "outputs": [],
   "source": [
    "# move model to GPU\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZNJ04uVN9Kj",
    "outputId": "9dd91432-41d4-4758-9d65-f33cf0f23fb7"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayeBbCCUN9Kk"
   },
   "source": [
    "Now we can implement a train method that will train the model. It takes as input the number of epochs, the model and the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZzvDe5EtN9Kk",
    "outputId": "1f15185a-d1fa-48b9-d95b-21f6ff3949ce"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "\n",
    "    # Train the model\n",
    "    cnn.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            # move data to GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # run model\n",
    "            output = cnn(images)\n",
    "            # compute loss function\n",
    "            loss = loss_func(output, labels)\n",
    "            # clear gradients for this training step\n",
    "            optimizer.zero_grad()\n",
    "            # backpropagation, compute gradients\n",
    "            loss.backward()\n",
    "            # apply update\n",
    "            optimizer.step()\n",
    "\n",
    "num_epochs = 10\n",
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1JWHUXEN9Kk"
   },
   "source": [
    "To check the performance of our network, we can run a prediction on our test data and check if the events are categorised correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSPZE9xDN9Kl"
   },
   "outputs": [],
   "source": [
    "def test(cnn, loaders):\n",
    "    test_prediction_list = []\n",
    "    test_label_list = []\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loaders['test']:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            test_output = cnn(images)\n",
    "            pred_labels = torch.max(test_output, dim=1)[1]\n",
    "            test_prediction_list.append(pred_labels)\n",
    "            test_label_list.append(labels)\n",
    "    test_label = torch.cat(test_label_list)\n",
    "    test_prediction = torch.cat(test_prediction_list)\n",
    "    return test_label.cpu(), test_prediction.cpu()\n",
    "\n",
    "test_label, test_prediction = test(cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeDhqDV5N9Kl",
    "outputId": "1bf29664-ad55-4eb7-d7c4-ff0846d1e340"
   },
   "outputs": [],
   "source": [
    "for i, label in enumerate(test_label[:10]):\n",
    "    print(f\"Predicted label: {test_prediction[i]}, True label: {label}; Prediction is {'correct' if test_prediction[i] == label else 'incorrect'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apO4nKlFN9Km"
   },
   "source": [
    "We can use [sklearn.metrics] to take a more detailed look into the performance, e.g. via creating a confusion matrix.\n",
    "\n",
    "[sklearn.metrics]: https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p60b7PwPN9Km",
    "outputId": "ce0bb3b9-404f-4744-d27b-24da8d21373b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Create confusion matrix and normalizes it over predicted (columns)\n",
    "confusion = confusion_matrix(test_label.numpy(), test_prediction.numpy(), normalize='pred')\n",
    "\n",
    "# Create a plot of the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ConfusionMatrixDisplay(confusion).plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2p5J5vwN9Kn"
   },
   "source": [
    "How can one improve the networks scores? We can add more Conv oder Dense layers to strenghten one part of your network! More Dense layers will increase your classification power, while more Conv layers will increase your propety filter power.\n",
    "We might also want to prevent overtraining, e.g. via including some Dropout layers."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
